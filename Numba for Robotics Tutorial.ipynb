{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numba for Robotics Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why use Numba for Robotics?\n",
    "\n",
    "Python has a lot of benefits for robotics - it allows fast prototyping of algorithms, and supports many useful libraries for numerical computations, machine learning, and computer vision. Furthermore, it also supports the Robotic Operating System ([ROS](http://wiki.ros.org/Documentation)) which provides basic frameworks and tools to develop code for robots. However, Python is also slower than compiled languages. Robotics algorithms often include many time-consuming and/or repetitive calculations. For example, a robot may need to process thousands or tens of thousands of data points from a laser sensor every second to find its location in a room. \n",
    "\n",
    "Because robotics has many repetitive calculations, and running code in real-time is important, we need some way to speed up Python code. [Numba](http://numba.pydata.org/) is a just-in-time compiler which greatly speeds up Python code, letting us run calculations like these in real time while still retaining all the other advantages of Python. Numba is especially great for speeding up loops, which can otherwise be quite slow. It also supports the numpy library for calculations with arrays. For a more comprehensive list of features supported by Numba, refer [here](http://numba.pydata.org/numba-doc/0.17.0/reference/pysupported.html). \n",
    "\n",
    "Numba accelerates Python code by generating a specialized implementation for the specific data types used in the code. Therefore to use Numba, your code must be structured to use only numba-supported data types. Numba focuses on numerical data types - it does not support some types such as dictionaries and has limited string processing support. This tutorial will teach you how to properly use Numba. We'll first go over a simple code example showing the basics, then see a robotics-specific example, using Numba to speed up a particle filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example: Use Numba to speed up computation\n",
    "\n",
    "We'll first use Numba to speed up some simple computations in Python. This section will teach you the common best practices of using Numba and demonstrate its benefits. First, make sure Numba is installed on your computer. In order to install Numba, check out these [instructions](http://numba.pydata.org/numba-doc/latest/user/installing.html). The following code defines the factorial function, which we'll use for a runtime comparison with Numba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def factorial(n):\n",
    "    result = 1\n",
    "    if (n < 0):\n",
    "        return np.nan\n",
    "    elif (n == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        for i in range(1, n+1):\n",
    "            result = result*i\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell which uses the `%timeit` function to calculate the runtime of the specified function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit factorial(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have checked the speed of the current function without using Numba, it is time to incorporate Numba into the code. \n",
    "\n",
    "First, import Numba into your code. Then, add the `@jit` function decorator, which Numba uses to indicate which function it should compile. You can see how the factorial function from above has Numba incorporated using the `@jit` function decorator below. Run the `%timeit` cell for the `factorial_jit` function below to check the speed, and you should notice that the runtime is much shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit #Step 1: import Numba\n",
    "\n",
    "@jit #Step 2: Add the @jit function decorator\n",
    "def factorial_jit(n):\n",
    "    result = 1\n",
    "    if (n < 0):\n",
    "        return np.nan\n",
    "    elif (n == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        for i in range(1, n+1):\n",
    "            result = result*i\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit factorial_jit(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@jit` compiles the decorated function on-the-fly to produce efficient machine code. This allows our functions to run at machine code speed, rather than the slower Python runtime. The just-in-time compilation can make the function slower at the first call. However, after the first use, Numba caches the function's machine code which makes it run faster than the first time since it does not need to compile again. If you did not see much of a decrease in runtime, it's likely because of this extra compilation time - try running `%timeit` again, and see if the runtime improves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numba Modes (Object mode vs nopython mode)\n",
    "\n",
    "In this section, we will learn about the two different compilation modes of Numba. These two modes are the object mode and the nopython mode. Object mode does not do any type-specialization making sure that the types used in the function are only the ones that Numba supports. In object mode, Numba compiles the parts of code that it can into machine code, and leaves the rest of the code for the Python interpreter. Even if Numba is completely unable to compile, `@jit` still runs the function and does not inform the user that Numba failed to enhance the code. For example, let's run the code sample below, which contains dictionaries. Numba is unable to compile code that uses dictionaries, so we might expect this to result in an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code with dictionary example\n",
    "from numba import jit\n",
    "\n",
    "alpha = {11: \"a\", 21: \"b\", 34: \"c\", 40: \"d\"}\n",
    "\n",
    "@jit\n",
    "def first_even_plc(d):\n",
    "    for key in d:\n",
    "        if (key % 2 == 0):\n",
    "            return d[key]\n",
    "        \n",
    "    return d[1]\n",
    "\n",
    "first_even_plc(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this code executes without crashing and simply generates a warning. This is not the ideal situation, since we might end up running code that we think is optimized, but actually isn't. We want to be notified when Numba fails to work. Therefore, Numba includes a \"nopython mode\" which enforces type-specialization, so that if Numba is unable to compile a piece of code, it will generate an error. The `@jit` function decorator first tries using the nopython mode, then switches to object mode if it fails in nopython mode. To enforce nopython mode, add a `nopython=True` parameter so, `@jit(nopython=True)`, or simply use `@njit`. Both of these are equivalent. Run the cell below which has the `@njit` function decorator instead of `@jit`, and you should see an error since dictionaries are not supported by Numba.\n",
    "\n",
    "To make sure Numba is accelerating your code, **it is best practice to always use nopython mode**, which enforces Numba type specialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, njit\n",
    "\n",
    "alpha = {11: \"a\", 21: \"b\", 34: \"c\", 40: \"d\"}\n",
    "\n",
    "@njit\n",
    "def first_even_plc(d):\n",
    "    for key in d:\n",
    "        if (key % 2 == 0):\n",
    "            return d[key]\n",
    "        \n",
    "    return d[1]\n",
    "\n",
    "first_even_plc(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other requirement of nopython mode is that Numba is not able to allocate memory for new arrays inside an `@njit` function. In this next example, we'll see how to structure code to deal with this limitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "def quad_eq(a,b,c):\n",
    "    roots = np.zeros(2)\n",
    "    d = b**2 - 4*a*c\n",
    "    if (d < 0):\n",
    "        return np.nan\n",
    "    x1 = (-b + math.sqrt(d))/(2*a)\n",
    "    x2 = (-b - math.sqrt(d))/(2*a)\n",
    "    roots[0] = x1\n",
    "    roots[1] = x2\n",
    "    \n",
    "    return roots\n",
    "\n",
    "quad_eq(1,8,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above needs to return two values, which it does by returning a numpy array. Check the current runtime of the function by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit quad_eq(1,8,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the problem with the previous function is that it returns a new numpy array, which is not allowed by Numba. Try adding the `@njit` function decorator to the `quad_eq` function to see what error you get. In Numba, functions are not allowed to create new arrays, because it is difficult for Numba to allocate new memory while also converting the code to machine code. To learn more about this, refer to this [link](http://numba.pydata.org/numba-doc/0.15.1/arrays.html). In order to fix this issue, we can simply pass an already allocated numpy array into the function and modify that in place. The following function does exactly that.  \n",
    "\n",
    "#### Exercise 1:\n",
    "Now let's try incorporating Numba into the following function by the steps mentioned previously. Make sure to use the `@njit` function decorator instead of the `@jit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "#TODO: import numba\n",
    "\n",
    "roots = np.zeros(2)\n",
    "#TODO: add function decorator\n",
    "def quad_eq_jitted(a,b,c,roots):\n",
    "    d = b**2 - 4*a*c\n",
    "    if (d < 0):\n",
    "        return np.nan\n",
    "    x1 = (-b + math.sqrt(d))/(2*a)\n",
    "    x2 = (-b - math.sqrt(d))/(2*a)\n",
    "    roots[0] = x1\n",
    "    roots[1] = x2\n",
    "\n",
    "quad_eq_jitted(1,8,1,roots)\n",
    "roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit quad_eq_jitted(1,8,1,roots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robotics example: Using Numba to speed up a particle filter\n",
    "\n",
    "Next, let's look at a robotics-specific example of how Numba speeds up repetitive calculations. This is an example of a particle filter, an algorithm used for localization of a robot. If you are unfamiliar with the particle filter, first watch [this video](https://www.youtube.com/watch?v=aUkBa1zMKv4).\n",
    "\n",
    "In a particle filter, there are four main steps. Let $x$ be the state of a particle, z be the measurements acquired by the robot's sensors, w be the weight of a particle, i be the particle number, and t be the iteration number.\n",
    " \n",
    "- Initialization: Sample particles from uniform distribution \n",
    "\n",
    "$ x_0^i \\sim p(x_0)$\n",
    "\n",
    "- Prediction: Predict the new states of the particles using the robot dynamics\n",
    "\n",
    "$ \\bar{x_0^i} \\sim p(x_t^i | x_{t-1}^i, u_t)$\n",
    "\n",
    "- Measurement Update: Update the weights of the particles using new measurements from robot\n",
    "\n",
    "$ w_t^i = p(z_t |\\bar{x_t^i} )$ \n",
    "\n",
    "- Resampling: Pick the particles with the highest weights for the next iteration\n",
    "\n",
    "The prediction, measurement update, and resampling steps are repeated for each particle, causing the algorithm to be slow when it uses many particles. In practice, particle filters may use hundreds or thousands of particles.\n",
    "\n",
    "For a more mathematical explanation, refer to [this paper](http://robots.stanford.edu/papers/thrun.pf-in-robotics-uai02.pdf). Since a particle filter repeats the same computations multiple times, we can expect a significant speedup by compiling these functions with Numba.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example problem, we have a robot moving around a 2D world. The robot has a sensor on it that measures the distance from the robot to 3 non-moving landmarks. This setup is shown in the figure below. The red circle is the robot and the pink squares are the landmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](map2.jpeg \"Map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `diffRobot_localizeRobot.txt` dataset contains these sensor measurements and the $\\omega$ (angular velocity) of the robot at each time-stamp, with a total of 500 data points collected over 50 seconds. The velocity of the robot is set to a constant. Furthermore, the dataset also contains the ground truth location of the robot at each timestamp, which is used to show the accuracy of the particle filter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `dynamics_function` of the particle filter. This function, which is used in the prediction step, updates the positions of the particles (`robot_pose`) given the controls used by the actual robot. At each time step, this function needs to be called once per each particle, so it's important to make it run quickly. Before completing Exercise 2, run the `%timeit` cell to understand the performance enhancement before and after Numba.\n",
    "\n",
    "#### Exercise 2:\n",
    "\n",
    "Below you will find the dynamics function without Numba incorporated into it. Follow the steps from previous exercises to speed up the function using Numba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "#TODO: Step 1: import Numba \n",
    "\n",
    "'''\n",
    "Arguments:\n",
    "robot_pose: position of a particle\n",
    "commands: the commands given to the robot (v,w)\n",
    "dt: the change in time\n",
    "\n",
    "Returns:\n",
    "Output of the function is the new particle position after the \n",
    "new commands are applied to the given position\n",
    "''' \n",
    "#TODO: step 2: add function decorator njit\n",
    "\n",
    "def dynamics_function(robot_pose, commands, dt):\n",
    "    theta = robot_pose[2]\n",
    "    dx = commands[0] * math.cos(theta) * dt \n",
    "    dy = commands[0] * math.sin(theta) * dt \n",
    "    dtheta = commands[1] * dt \n",
    "    new_pose = np.array([robot_pose[0] + dx, robot_pose[1] + dy, robot_pose[2] + dtheta])\n",
    "        \n",
    "    return new_pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, run the cell below after completing Exercise 2 to get the new run-time of the dynamics function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%timeit dynamics_function(np.array([1,1,0.5]), np.array([0.5, 0.1]), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now also look at the unmodified `measurement_function` in the cell below. The following code is the measurement function of the particle filter, which calculates the expected measurements to each of the landmarks on the map for each particle. By comparing these expected measurements to the actual observations, we can figure out which particles are more accurate guesses of where the robot is. The `measurement_funcion` currently uses datatypes not supported in Numba. As seen in the previous section, using `@njit` with the current function will cause errors. \n",
    "\n",
    "For the next exercise, try looking for data types that don’t work with Numba in the code below. Using this [link](https://numba.pydata.org/numba-doc/dev/reference/pysupported.html) as a reference, change those data types in the code. Modify the code such that it works with Numba, and `@njit` does not cause any errors.\n",
    "\n",
    "#### Exercise 3:\n",
    "\n",
    "Incorporate Numba into the measurement function given below. First, make sure to import Numba and add the function decorator as shown before. The function uses a dictionary, which is not supported in Numba. One recommendation is to use a numpy array instead of the dictionary. Lastly, we are not allowed to allocate new memory inside the function, so to fix that issue, refer to the code from Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#TODO: Step 1: import Numba \n",
    "'''\n",
    "Arguments:\n",
    "robot_pose: position of a particle\n",
    "tags_dict: the landmark locations on the map given as a dictionary\n",
    "\n",
    "Returns:\n",
    "Output of the function is the measurement we expect the robot to see \n",
    "at the given robot_pose.\n",
    "The measurement is formatted as a dict of {landmark_number: landmark_measurement}\n",
    "''' \n",
    "#TODO: step 2: add function decorator njit\n",
    "def measurement_function(robot_pose, tags_dict):\n",
    "    #TODO: step 3: change datatypes to ones that support Numba\n",
    "    #TODO: step 4: make sure you are not allocating new memory in the function\n",
    "    measurement = {}\n",
    "    for tag_number in range(0,3):\n",
    "        tag_pose = tags_dict[tag_number]\n",
    "        measurement[tag_number] = tag_pose - robot_pose[:2]\n",
    "    return measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to check the runtime of the `measurement_function` before and after Numba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_dict = {}\n",
    "tags_dict[0] = [0.75, -1.25]\n",
    "tags_dict[1] = [-1.1, 0.8]\n",
    "tags_dict[2] = [1.5, 2.1]\n",
    "\n",
    "# The numpy array with the landmark locations on the map is provided when testing with jit\n",
    "tags_arr = np.zeros((3,2))\n",
    "tags_arr[0] = [0.75, -1.25]\n",
    "tags_arr[1] = [-1.1, 0.8]\n",
    "tags_arr[2] = [1.5, 2.1]\n",
    "\n",
    "%timeit measurement_function(np.array([1,1,0.5]), tags_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will look at the whole particle filter code below with all the necessary modifications needed already in place. Here we simply read a text file in order to get all the data necessary to run our particle filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "import math\n",
    "from numba import njit\n",
    "\n",
    "\n",
    "#actual landmark values as numpy array\n",
    "tags_arr = np.zeros((3,2))\n",
    "tags_arr[0] = [0.75, -1.25]\n",
    "tags_arr[1] = [-1.1, 0.8]\n",
    "tags_arr[2] = [1.5, 2.1]\n",
    "\n",
    "#actual landmark values as dictionary\n",
    "tags_dict = {}\n",
    "tags_dict[0] = [0.75, -1.25]\n",
    "tags_dict[1] = [-1.1, 0.8]\n",
    "tags_dict[2] = [1.5, 2.1]\n",
    "\n",
    "incr = 0\n",
    "speed = 0.5 #stays constant\n",
    "data = open('diffRobot_localizeRobot.txt', 'r')\n",
    "lines = data.readlines()\n",
    "\n",
    "dataSet = [] #arrays of time, control, landamrks 1 to 4\n",
    "robot = []\n",
    "\n",
    "for line in lines:\n",
    "    time, robotState, control, landmark1, landmark2, landmark3, landmark4 = line.split(\",\")\n",
    "\n",
    "    robotState = robotState[2:-1]\n",
    "    rx, ry, theta = robotState.split()\n",
    "    robotState = []\n",
    "    rx = float(rx)\n",
    "    ry = float(ry)\n",
    "    theta = float(theta)\n",
    "    robotState.append(rx)\n",
    "    robotState.append(ry)\n",
    "    robotState.append(theta)\n",
    "\n",
    "    robot.append(robotState)\n",
    "\n",
    "    control = control[2:-1]\n",
    "    control = float(control)\n",
    "    time = float(time)\n",
    "\n",
    "    landmark2 = landmark2[2:-1]\n",
    "    l1, l2 = landmark2.split()\n",
    "    landmark2 = []\n",
    "    l1 = float(l1)\n",
    "    l2 = float(l2)\n",
    "    landmark2.append(l1)\n",
    "    landmark2.append(l2)\n",
    "\n",
    "    landmark3 = landmark3[2:-1]\n",
    "    l1, l2 = landmark3.split()\n",
    "    landmark3 = []\n",
    "    l1 = float(l1)\n",
    "    l2 = float(l2)\n",
    "    landmark3.append(l1)\n",
    "    landmark3.append(l2)\n",
    "\n",
    "    landmark4 = landmark4[2:-2]\n",
    "    l1, l2 = landmark4.split()\n",
    "    landmark4 = []\n",
    "    l1 = float(l1)\n",
    "    l2 = float(l2)\n",
    "    landmark4.append(l1)\n",
    "    landmark4.append(l2)\n",
    "\n",
    "    new = []\n",
    "    new.append(time)\n",
    "    new.append(control)\n",
    "    new.append(landmark2)\n",
    "    new.append(landmark3)\n",
    "    new.append(landmark4)\n",
    "    dataSet.append(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the functions that we are using in order to build our filter. We will create two particle filters, one with Numba and one without, for direct comparison. Most of these functions in the particle filter use the `@njit` function decorator, but some do not. Can you figure out why some of them are not supported by Numba?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below shows the `create_uniform_particles` function which creates random particles with a uniform distribution in the beginning. There are only slight differences between these two functions. The one with Numba takes an extra parameter, since Numba functions are not allowed to allocate new memory to create arrays. So, this is again another example of changing something in place when using Numba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uniform_particles(spanX1, spanX2, spanY1, spanY2, spanTheta1, spanTheta2, numParticles=200):\n",
    "    particleSet = np.zeros([numParticles, 3])\n",
    "    xSamples = np.random.uniform(spanX1, spanX2, numParticles)\n",
    "    ySamples = np.random.uniform(spanY1, spanY2, numParticles)\n",
    "    thetaSamples = np.random.uniform(spanTheta1, spanTheta2, numParticles)\n",
    "    for i in range(0, numParticles):\n",
    "        particleSet[i, :] = [xSamples[i], ySamples[i], thetaSamples[i]]\n",
    "    return particleSet\n",
    "\n",
    "@njit\n",
    "def create_uniform_particles_jit(spanX1, spanX2, spanY1, spanY2, spanTheta1, spanTheta2, particleSet, numParticles=200):\n",
    "    xSamples = np.random.uniform(spanX1, spanX2, numParticles)\n",
    "    ySamples = np.random.uniform(spanY1, spanY2, numParticles)\n",
    "    thetaSamples = np.random.uniform(spanTheta1, spanTheta2, numParticles)\n",
    "    for i in range(0, numParticles):\n",
    "        particleSet[i, :] = [xSamples[i], ySamples[i], thetaSamples[i]]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the `measurement_function` again. There are two of them - one that uses Numba and one that doesn't. As seen in the exercise above, the one without Numba uses dictionaries and creates new objects, which are not allowed in Numba nopython mode. Copy your new `measurement_function` from exercise 3 inside the `measurement_function_jit` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement_function(robot_pose, tags_dict):\n",
    "    measurement = {}\n",
    "    for tag_number in range(0,3):\n",
    "        tag_pose = tags_dict[tag_number]\n",
    "        measurement[tag_number] = tag_pose - robot_pose[:2]\n",
    "    return measurement\n",
    "\n",
    "@njit\n",
    "def measurement_function_jit(robot_pose, tags_arr, measurement):\n",
    "    # TODO: insert new function from exercise 3 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's compare the two `update` functions. The update function, without Numba incorporated, uses the multivariate pdf function from the scipy library. However, Numba does not support this function so the `calc_pdf` function which does the exact same computation was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(particles, particleWeights, tags_dict, robo_tags):\n",
    "    sigma = np.array([[0.1, 0], [0, 0.1]])\n",
    "\n",
    "    for j in range(0, len(particles)):\n",
    "        measurement = measurement_function(particles[j], tags_dict)\n",
    "        \n",
    "        particleWeight = 1\n",
    "        for id in range(0,3):\n",
    "            particleWeight *= mvn.pdf(np.array(measurement.get(id)), mean=robo_tags[id], cov=sigma)\n",
    "        particleWeights[j] = particleWeight\n",
    "\n",
    "    # re-scale the particle weights so that the sum of weights = 1\n",
    "    particleWeights /= sum(particleWeights)\n",
    "\n",
    "    return particleWeights\n",
    "\n",
    "@njit\n",
    "def calc_pdf(x, mu, sigma):\n",
    "    k = len(x)\n",
    "    sig_det = np.linalg.det(sigma)\n",
    "    sig_inv = np.linalg.inv(sigma)\n",
    "    G = ( 1/ ( np.sqrt(((2*np.pi)**k)*sig_det) ) )\n",
    "    G *= np.exp( - (0.5 * (x - mu).T.dot(sig_inv).dot( (x - mu) ) ) )\n",
    "    return G\n",
    "\n",
    "@njit\n",
    "def update_jit(particles, particleWeights, tags_arr, robo_tags, measurement):\n",
    "    sigma = np.array([[0.1, 0], [0, 0.1]])\n",
    "    \n",
    "    for j in range(0, len(particles)):\n",
    "        robot_pose = particles[j]\n",
    "        measurement_function_jit(particles[j], tags_arr, measurement)\n",
    "    \n",
    "        particleWeight = 1\n",
    "        for id in range(0,3):\n",
    "            particleWeight *= calc_pdf(measurement[id], robo_tags[id], sigma)\n",
    "    \n",
    "        particleWeights[j] = particleWeight\n",
    "\n",
    "    # re-scale the particle weights so that the sum of weights = 1\n",
    "    particleWeights /= np.sum(particleWeights)\n",
    "\n",
    "    return particleWeights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some of the other functions that are used for the particle filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def dynamics_function_jit(robot_pose, commands, dt):\n",
    "    theta = robot_pose[2]\n",
    "    dx = speed * math.cos(theta) * dt \n",
    "    dy = speed * math.sin(theta) * dt \n",
    "    dtheta = commands * dt \n",
    "    new_pose = np.array([robot_pose[0] + dx, robot_pose[1] + dy, robot_pose[2] + dtheta])\n",
    "        \n",
    "    return new_pose\n",
    "\n",
    "def dynamics_function(robot_pose, commands, dt):\n",
    "    theta = robot_pose[2]\n",
    "    dx = speed * math.cos(theta) * dt \n",
    "    dy = speed * math.sin(theta) * dt \n",
    "    dtheta = commands * dt \n",
    "    new_pose = np.array([robot_pose[0] + dx, robot_pose[1] + dy, robot_pose[2] + dtheta])\n",
    "        \n",
    "    return new_pose\n",
    "\n",
    "def predict(particles, commands, dt):\n",
    "    for i in range(0, len(particles)):\n",
    "      particles[i] = dynamics_function(particles[i], commands, dt)\n",
    "      particles[i] = np.random.normal(loc = particles[i], scale = sigma)\n",
    "    return particles\n",
    "\n",
    "def resample(particleWeights, particleSet, numParticles, selectedIndices):\n",
    "    newParticles = np.zeros((numParticles, 3))\n",
    "    for j in range(0, len(selectedIndices)):\n",
    "        # new particle set is being created\n",
    "        newParticles[j] = particleSet[selectedIndices[j]]\n",
    "    return newParticles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our main particle filter. The `numParticles` parameter is the number of particles used by the filter. The larger the number of particles, the more time each iteration takes to run.\n",
    "\n",
    "There are two particle filters below - one with Numba (`p_filter_jit`) and one without Numba (`p_filter`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sensor noise\n",
    "sigma = np.array([0.05, 0.05, 0.1])\n",
    "sigma2 = np.array([[0.1, 0], [0, 0.1]])\n",
    "\n",
    "#particle filter - without jit\n",
    "def p_filter(numParticles):\n",
    "    allPsets = []\n",
    "    particleSet = create_uniform_particles(-4, 4, -4, 4, 0, 2*math.pi, numParticles)\n",
    "    #change in time\n",
    "    dt = 0\n",
    "    for i in range(0, len(dataSet)):\n",
    "        allPsets.append(particleSet)\n",
    "        control = dataSet[i][1] # control value\n",
    "        if (i < len(dataSet) - 1):\n",
    "            dt = math.fabs(dataSet[i + 1][0] - dataSet[i][0]) #diff betwn 2 consecutive time stamps\n",
    "        else:\n",
    "            dt = dt\n",
    "\n",
    "        #update location using dynamics\n",
    "        particleSet = predict(particleSet, control, dt)\n",
    "\n",
    "        robo_tags = np.zeros((3, 2))\n",
    "        for l in range(2, 5):\n",
    "            robo_tags[l-2] = [dataSet[i][l][0], dataSet[i][l][1]]\n",
    "\n",
    "        # Generate particle weights\n",
    "        particleWeights = np.zeros(numParticles)\n",
    "        particleWeights = update(particleSet, particleWeights, tags_dict, robo_tags)\n",
    "\n",
    "        #resampling\n",
    "        particleIndices = range(0, numParticles)\n",
    "        selectedIndices = np.random.choice(particleIndices, numParticles, p=particleWeights)\n",
    "        particleSet = resample(particleWeights, particleSet, numParticles, selectedIndices)\n",
    "        \n",
    "        \n",
    "    return allPsets\n",
    "    \n",
    "\n",
    "#particle filter - with jit\n",
    "def p_filter_jit(numParticles):\n",
    "    allPsets = []\n",
    "    particleSet = np.zeros([numParticles, 3])\n",
    "    create_uniform_particles_jit(-4, 4, -4, 4, 0, 2*math.pi, particleSet, numParticles)\n",
    "    #change in time\n",
    "    dt = 0\n",
    "    for i in range(0, len(dataSet)):\n",
    "        allPsets.append(particleSet)\n",
    "        control = dataSet[i][1] # control value\n",
    "        if (i < len(dataSet) - 1):\n",
    "            dt = math.fabs(dataSet[i + 1][0] - dataSet[i][0]) #diff betwn 2 consecutive time stamps\n",
    "        else:\n",
    "            dt = dt\n",
    "\n",
    "        #update location using dynamics\n",
    "        particleSet = predict(particleSet, control, dt)\n",
    "\n",
    "        robo_tags = np.zeros((3, 2))\n",
    "        for l in range(2, 5):\n",
    "            robo_tags[l-2] = [dataSet[i][l][0], dataSet[i][l][1]]\n",
    "\n",
    "        # Generate particle weights\n",
    "        particleWeights = np.zeros(numParticles)\n",
    "        measurement = np.zeros((3, 2))\n",
    "        particleWeights = update_jit(particleSet, particleWeights, tags_arr, robo_tags, measurement)\n",
    "\n",
    "        #resampling\n",
    "        particleIndices = range(0, numParticles)\n",
    "        selectedIndices = np.random.choice(particleIndices, numParticles, p=particleWeights)\n",
    "        particleSet = resample(particleWeights, particleSet, numParticles, selectedIndices)\n",
    "        \n",
    "    return allPsets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cells below to see the end result of the particle filter. The pink squares are the landmarks, the red circle is the robot, and the yellow particles are the particles after each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psets = p_filter_jit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "\n",
    "## Plotting code\n",
    "def graph(particleSet, roboPose):\n",
    "    fig = plt.figure(1)\n",
    "\n",
    "    for j in range(0, 3):\n",
    "        plt.plot(tags_arr[j, 0], tags_arr[j, 1], 's',\n",
    "                             markersize=10, color='pink')\n",
    "\n",
    "    for j in range(0, len(particleSet)):\n",
    "        plt.plot(particleSet[j,0], particleSet[j, 1], 'o', markersize= 3, color='y')\n",
    "\n",
    "    plt.plot(roboPose[0], roboPose[1], 'o', markersize=6, color='r')\n",
    "\n",
    "    plt.xlabel('X distance (m)')\n",
    "    plt.ylabel('Y distance (m)')\n",
    "    plt.axis([-5, 5, -5, 5])\n",
    "    plt.show()\n",
    "\n",
    "##animating - plotting all the saved particlesets\n",
    "for i in range(len(psets)):\n",
    "    particleSet = psets[i]\n",
    "    graph(particleSet, robot[i])\n",
    "    sleep(0.00001)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the `%timeit` cells below to see how much Numba optimized the particle filter. The `p_filter` and the `p_filter_jit` functions both take in the number of particles as an argument. Try changing this value to different numbers to see how as the number of particles increases, Numba enhancement becomes more impactful.\n",
    "\n",
    "*You may stop the cell above which is animating the particle filter to be able to run the next cells.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit p_filter(10) ##runtime of particle filter without Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit p_filter_jit(10) ##runtime of particle filter with Numba"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
